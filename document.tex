\documentclass[a4paper, 11pt, twocolumn]{article} % Font encoding and italian language support
\usepackage[T1]{fontenc} 
\usepackage[utf8]{inputenc}
\usepackage{charter}
\usepackage[libertine]{newtxmath}
%\usepackage[italian]{babel}

\usepackage{graphicx} % Manage pictures
\usepackage[pdfa]{hyperref} % Reference Links



\usepackage{color} % Allows defining colors for code snippets
\usepackage{setspace} % Sets leading
\usepackage[a4paper, inner=0.5cm, outer=0.5cm, lmargin=1.5cm, rmargin=1.5cm, tmargin=2cm, bmargin=2cm]{geometry} % Sets margins and borders

\usepackage{listings}
\definecolor{dkgreen}{rgb}{0.1,0.5,0.1}
\definecolor{greengray}{rgb}{0.32,0.57,0.32}
\definecolor{orange}{rgb}{0.96,0.42,0}
\definecolor{lightblue}{rgb}{0,0.28,0.95}
\definecolor{background}{rgb}{0.995,0.995,0.995}
\lstset {
        frame=tb,
        language=matlab,
        aboveskip=3mm,
        belowskip=3mm,
        showstringspaces=false,
        columns=flexible,
        basicstyle={\small\ttfamily},
        numbers=none,
        backgroundcolor=\color{background},
        numberstyle=\tiny\color{drkgeen},
        keywordstyle=\color{lightblue},
        commentstyle=\color{greengray},
        stringstyle=\color{orange},
        breaklines=true,
        breakatwhitespace=true,
        tabsize=3
}

\setlength{\parindent}{0pt}

\begin{document}

\setstretch{1.2} % Sets leading to 1.5


\title{CNN Classifier}
\author{Giovanni Battilana, Marzia Paschini, Marco Sgobino}
\maketitle
\tableofcontents % Prints table of contents
%\newpage
%\clearpage

\section{Assignment general description}

This project requires the implementation of an image classifier based on convolutional neural networks. The provided dataset (from [Lazebnik et al., 2006]), contains 15 categories (office, kitchen, living room, bedroom, store, industrial, tall building, inside city, street, highway, coast, open country, mountain, forest, suburb), and is already divided in training set and test set.


\section{Goal of this paper}

This paper had 3 goals of increasing difficulty:

\begin{enumerate}
    \item building a \emph{shallow network} with a layout specified from the Teacher in order to have a \emph{baseline} network to allow further comparisons. Such baseline should be improved in the subsequent sections;
    \item improving the previous baseline network and compare results with the baseline. Comments on strategies adopted should be provided;
    \item adopting \emph{transfer learning} based on the pre-trained network \emph{AlexNet}.
\end{enumerate}

\section{Adopted tools}

Students adopted the programming language and numeric computing environment \textbf{MATLAB} as both text editor and simulation software to describe, implement and build the trained networks. 

Specific MATLAB Toolbox were needed \--- the project should require \emph{Deep Learning Toolbox}, \emph{Computer Vision Toolbox} and \emph{Image Processing Toolbox}. Optionally, to improve processing speed during the convolutional neural network build phase, students installed and enabled the \emph{Parallel Computing Toolbox}.






\section{Training a baseline network}

The first step was the building a baseline network (a shallow network), whose layout had been assigned by the teacher. In practice, this phase required to strictly follow given requirements in order to obtain \emph{an overall test accuracy of around} $30\%$.

\subsection{Importing the dataset} 

The training dataset comprises $1500$ images, of 15 categories (office, kitchen, living room, bedroom, store, industrial, tall building, inside city, street, highway, coast, open country, mountain, forest, suburb). Each photo lies inside a directory, whose name denotes the category. Similarly, the test dataset comprises $2985$ pictures lying in the same categories.

In order to import the dataset into an \emph{image datastore} object, students used following instructions,

\begin{lstlisting}
TrainDatasetPath = fullfile('dataset', 'train');

imds = imageDatastore(TrainDatasetPath, ...
    'IncludeSubfolders', true,...
    'LabelSource', 'foldernames');
\end{lstlisting}

Each image in the dataset had its own \--- non common \--- size. Moreover, images do not share a common aspect ratio. In order to obtain a shared size and aspect ratio, students have chosen to follow the simple approach of \emph{rescaling the whole image independently along the vertical and the horizontal axis}, in order to achieve the proper size. As will be shown later, the chosen aspect ratio will be $1:1$ (a square).

\subsection{Requirements}
Layout of the network is described in the following Table:
\bigskip

\begin{footnotesize}
\begin{tabular}{|c|c|c|}
\hline 
\# & type & size \\
\hline \hline 
1 & Image input & $64 \times 64 \times 1$ images \\
\hline 
2 & Convolution & $8 \mbox{ } 3 \times 3$ convolutions, stride 1 \\
\hline 
3 & ReLU &  \\
\hline 
4 & Max Pooling & $2 \times 2$ max pooling, stride 2 \\
\hline
5 & Convolution & $16 \mbox{ } 3 \times 3$ convolutions, stride 1 \\
\hline 
6 & ReLU &  \\
\hline 
7 & Max Pooling & $2 \times 2$ max pooling, stride 2 \\
\hline
8 & Convolution & $32 \mbox{ } 3 \times 3$ convolutions, stride 1 \\
\hline 
9 & ReLU & \\
\hline 
10 & Fully Connected & $15$ \\
\hline
11 & Softmax & softmax \\ 
\hline \hline 
12 & Classification & crossentropyex \\
\hline
\end{tabular}
\end{footnotesize}
\bigskip

Other non-optional requirements were the following ones,

\begin{itemize}
    \item using input images of size $64 \times 64$ (as shown in layer $1$ of previous Table);
    \item use $85\%$ of the provided dataset for the training set and the remaining portion for the validation set, so that each label is properly split with the same percentage;
    \item employ \textbf{stochastic gradient descent with momentum} as the optimization algorithm;
    \item adopt \emph{minibatches} of size $32$;
    \item initial weights should be drawn from a Gaussian distribution with a mean of $0$ and a standard deviation of $0.01$. Initial bias values should be set to $0$;
    \item choose a stopping criterion;
\end{itemize}

\subsection{Splitting the dataset}

To split the dataset as requested, students wrote and ran the following code:

\begin{lstlisting}
trainQuota=0.85;
[imdsTrain, imdsValidation] = splitEachLabel(imds, trainQuota,...
    'randomize');
\end{lstlisting}

These instructions were sufficient to obtain two, distinct, datasets \--- the first one for training, the second one for validation. Images should be elected and put in the datasets according to a random process; despite that, \texttt{splitEachLabel} function should assure that the same quota of $0.85$ for training sets was maintained across all $15$ labels.

\subsection{Resizing images}

In order to resize images to match the requested size of $64 \times 64$, students ran:

\begin{lstlisting} 
imds.ReadFcn = @(x)imresize(imread(x),...
                            [64 64]);
\end{lstlisting}

This command should overload the \texttt{ReadFcn} function inside \texttt{imds}, so that instead of simply reading images they should be resized too.

\subsection{Layers definition}

Layers layout is specified in the provided Table. In order to obtain such layout, the students organized the network layout information in a single object named \texttt{layers}, such as

\begin{lstlisting}
layers = [
    imageInputLayer([64 64 1],'Name','input')
    
    convolution2dLayer(3,8,...
        'Padding','same',...
        'Stride', [1 1],...
        'Name','conv_1',...
        'WeightsInitializer',...
        @(sz) randn(sz)*0.01,...
        'BiasInitializer',...
        @(sz) zeros(sz))

    reluLayer('Name','relu_1')

    maxPooling2dLayer(2,'Stride',2,...
        'Name','maxpool_1')

    convolution2dLayer(3,16,...
        'Padding','same',...
        'Stride', [1 1],...
        'Name','conv_2',...
        'WeightsInitializer',...
        @(sz) randn(sz)*0.01,...
        'BiasInitializer',...
        @(sz) zeros(sz))

    reluLayer('Name','relu_2')

    maxPooling2dLayer(2,'Stride',2,...
        'Name','maxpool_2')

    convolution2dLayer(3,32,...
        'Padding','same',...
        'Stride', [1 1],...
        'Name','conv_3',...
        'WeightsInitializer',...
        @(sz) randn(sz)*0.01,...
        'BiasInitializer',...
        @(sz) zeros(sz))

    reluLayer('Name','relu_3')

    fullyConnectedLayer(15,...
        'Name','fc_1',...
        'WeightsInitializer',...
        @(sz) randn(sz)*0.01,...
        'BiasInitializer',...
        @(sz) zeros(sz))

    softmaxLayer('Name','softmax')
    classificationLayer('Name','output')
];

\end{lstlisting}

A peculiar aspects of this representation is the weights initialization, which is handled by the function handle \texttt{@(sz) randn(sz)*0.01}, which should yield proper random numbers for normally-distributed weights initialization with standard deviation $0.01$. 

Similarly, \texttt{@(sz) zeros(sz)*0.01} will generate the null vectors required to initialize the biases.

A name should be assigned to each layer, while the defined network may be visually inspected with the commands

\begin{lstlisting}
lgraph = layerGraph(layers);
analyzeNetwork(lgraph)
\end{lstlisting}

\subsection{Network training options}

Options for training the network should be provided. In order to satisfy the requirements, students set the following options in an object,

\begin{lstlisting}
options = trainingOptions('sgdm', ...
    'InitialLearnRate', InitialLearningRate, ...
    'ValidationData',imdsValidation, ... 
    'MiniBatchSize',32, ...
    'ExecutionEnvironment','parallel',...
    'Plots','training-progress'...
);

\end{lstlisting}

where the quantity \texttt{InitialLearningRate} should be properly fine-tuned.

Each option is necessary, with the sole exception of \texttt{ExecutionEnvironment}, which enables parallel computing capabilities:

\begin{itemize}
    \item \texttt{sgdm}: the optimization algorithm in use, as in requirements; 
    \item \texttt{ValidationData}: specifies the image datastore to use when validating the error, during the training;
    \item \texttt{MiniBatchSize}: set to $32$ as in requirements;
    \item \texttt{Plots}: enables a visual inspection of the training process, useful to spot possible signs of overfitting;
\end{itemize}

Every other option is left as default.

\subsection{Training the network and obtaining the accuracy}

The following command will begin the network training with specified layout and options,

\begin{lstlisting}
net = trainNetwork(imdsTrain, layers, options);
\end{lstlisting} 

In order to collect the accuracy with the provided test set, the students implemented the following code,

\begin{lstlisting}
TestDatasetPath = fullfile('dataset', 'test');
imdsTest = imageDatastore(TestDatasetPath, ...
    'IncludeSubfolders', true,...
    'LabelSource', 'foldernames');
imdsTest.ReadFcn = @(x)imresize(imread(x),...
                    [64 64]);

YPredicted = classify(net, imdsTest);
YTest = imdsTest.Labels;

accuracy = sum(YPredicted == YTest) / numel(YTest);
\end{lstlisting}

TODO

\subsection{Fine-tuning initial learning rate}

In order to fine-tune the initial learning rate, manual trials along with manual inspection was required. Values of $0.1$, $0.01$, $0.001$ and $0.0001$ (representatives of various order of magnitude) were tried.

Only values in the neighborhood of $0.001$ gave the required performance of around $30\%$. In particular, testing the network $5$ times, and collecting the accuracy TODO

\section{Improving the network}

\section{Adopting transfer learning with AlexNet}


\end{document}
