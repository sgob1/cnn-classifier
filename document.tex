\documentclass[a4paper, 11pt]{article} % Font encoding and italian language support
\usepackage[T1]{fontenc} 
\usepackage[utf8]{inputenc}
\usepackage{charter}
\usepackage[libertine]{newtxmath}
%\usepackage[italian]{babel}

\usepackage{graphicx} % Manage pictures
\usepackage[pdfa]{hyperref} % Reference Links



\usepackage{color} % Allows defining colors for code snippets
\usepackage{setspace} % Sets leading
\usepackage[a4paper, inner=0.5cm, outer=0.5cm, lmargin=2cm, rmargin=2cm, tmargin=2.5cm, bmargin=2.5cm]{geometry} % Sets margins and borders

\usepackage{listings}
\definecolor{dkgreen}{rgb}{0.1,0.5,0.1}
\definecolor{greengray}{rgb}{0.32,0.57,0.32}
\definecolor{orange}{rgb}{0.96,0.42,0}
\definecolor{lightblue}{rgb}{0,0.28,0.95}
\definecolor{background}{rgb}{0.995,0.995,0.995}
\lstset {
        frame=tb,
        language=matlab,
        aboveskip=3mm,
        belowskip=3mm,
        showstringspaces=false,
        columns=flexible,
        basicstyle={\small\ttfamily},
        numbers=none,
        backgroundcolor=\color{background},
        numberstyle=\tiny\color{drkgeen},
        keywordstyle=\color{lightblue},
        commentstyle=\color{greengray},
        stringstyle=\color{orange},
        breaklines=true,
        breakatwhitespace=true,
        tabsize=3
}

\setlength{\parindent}{0pt}

\begin{document}

\setstretch{1.25} % Sets leading to 1.5


\title{CNN Classifier}
\author{Giovanni Battilana, Marzia Paschini, Marco Sgobino}
\maketitle
\tableofcontents % Prints table of contents
%\newpage
%\clearpage

\section{Assignment general description}

This project requires the implementation of an image classifier based on Convolutional Neural Networks. The provided dataset (from [Lazebnik et al., 2006]), contains 15 categories (office, kitchen, living room, bedroom, store, industrial, tall building, inside city, street, highway, coast, open country, mountain, forest, suburb), and is already divided in training set and test set.


\section{Goal of this paper}

This paper had 3 goals of increasing difficulty:

\begin{enumerate}
    \item building a \emph{shallow network} with a layout specified from the Teacher in order to have a \emph{baseline} network to allow further comparisons. Such baseline should be the reference from which subsequent improvements are evaluated;
    \item improving the previous baseline network and compare results with the baseline. Comments on strategies adopted should be provided;
    \item adopting \emph{transfer learning} based on the pre-trained network \emph{AlexNet}. Comments on performance improvements should be given.
\end{enumerate}

\section{Adopted tools}

Students adopted the programming language and numeric computing environment \textbf{MATLAB} as both text editor and simulation software to describe, implement and build the trained networks. 

Specific MATLAB Toolbox were needed \--- the project should require \emph{Deep Learning Toolbox}, \emph{Computer Vision Toolbox} and \emph{Image Processing Toolbox}. Optionally, to improve processing speed during the Convolutional Neural Network build phase, students installed and enabled the \emph{Parallel Computing Toolbox}.






\section{Training a baseline network}

The first step was the building a baseline network (a shallow network), whose layout had been assigned by the Teacher. In practice, this phase required to strictly follow given requirements in order to obtain \emph{an overall test accuracy of around} $30\%$.

\subsection{Importing the dataset} 

The training dataset comprises $1500$ images, of 15 categories (office, kitchen, living room, bedroom, store, industrial, tall building, inside city, street, highway, coast, open country, mountain, forest, suburb). Each photo lies inside a directory, whose name denotes the category. Similarly, the test dataset comprises $2985$ pictures lying in the same categories.

In order to import the dataset into an \emph{image datastore} object, students used following instructions,

\begin{lstlisting}
TrainDatasetPath = fullfile('dataset', 'train');
imds = imageDatastore(TrainDatasetPath, 'IncludeSubfolders', true, 'LabelSource', 'foldernames');
\end{lstlisting}

Each image in the dataset had its own \--- non common \--- size. Moreover, images do not share a common aspect ratio. In order to obtain a shared size and aspect ratio, the group has chosen to follow the simple approach of \emph{rescaling the whole image independently along the vertical and the horizontal axis}, in order to achieve the proper size. As will be shown later, the chosen aspect ratio will be of $1:1$ (a square).

\subsection{Requirements}
Layout of the network is described in the following Table:
\bigskip

\begin{center}
\begin{tabular}{|c|c|c|}
\hline 
\# & layer type & size and parameters \\
\hline \hline 
1 & Image input & $64 \times 64 \times 1$ images \\
\hline 
2 & Convolution & $8 \mbox{ } 3 \times 3$ convolutions, stride 1 \\
\hline 
3 & ReLU &  \\
\hline 
4 & Max Pooling & $2 \times 2$ max pooling, stride 2 \\
\hline
5 & Convolution & $16 \mbox{ } 3 \times 3$ convolutions, stride 1 \\
\hline 
6 & ReLU &  \\
\hline 
7 & Max Pooling & $2 \times 2$ max pooling, stride 2 \\
\hline
8 & Convolution & $32 \mbox{ } 3 \times 3$ convolutions, stride 1 \\
\hline 
9 & ReLU & \\
\hline 
10 & Fully Connected & $15$ \\
\hline
11 & Softmax & softmax \\ 
\hline \hline 
12 & Classification & crossentropyex \\
\hline
\end{tabular}
\end{center}
\bigskip

Other non-optional requirements were the following ones,

\begin{itemize}
    \item using input images of size $64 \times 64$ (as shown in layer $1$ of previous Table);
    \item use $85\%$ of the provided dataset for the training set and the remaining portion for the validation set, so that each label is properly split with the same percentage;
    \item employ \textbf{stochastic gradient descent with momentum} as the optimization algorithm;
    \item adopt \emph{minibatches} of size $32$;
    \item initial weights should be drawn from a Gaussian distribution with a mean of $0$ and a standard deviation of $0.01$. Initial bias values should be set to $0$;
    \item choose a stopping criterion;
\end{itemize}

\subsection{Splitting the dataset}

To split the dataset as requested, students wrote and ran the following code:

\begin{lstlisting}
trainQuota=0.85;
[imdsTrain, imdsValidation] = splitEachLabel(imds, trainQuota, 'randomize');
\end{lstlisting}

These instructions were sufficient to obtain two, distinct, datasets \--- the first one for training, the second one for validation. Images should be elected and put in the datasets according to a random process; despite that, \texttt{splitEachLabel} function should assure that the same quota of $0.85$ for training sets was maintained across all $15$ labels.

\subsection{Resizing images}

In order to resize images to match the requested size of $64 \times 64$, students ran:

\begin{lstlisting} 
imds.ReadFcn = @(x)imresize(imread(x), [64 64]);
\end{lstlisting}

This command should overload the \texttt{ReadFcn} function inside \texttt{imds}, so that instead of simply reading images they should be resized too.

\subsection{Layers definition}

Layers layout is specified in the provided Table. In order to obtain such layout, the students organized the network layout information in a single object named \texttt{layers}, such as

\begin{lstlisting}
layers = [
    imageInputLayer([64 64 1],'Name','input')
    
    convolution2dLayer(3,8, 'Padding','same', 'Stride', [1 1], 'Name','conv_1',...
        'WeightsInitializer', @(sz) randn(sz)*0.01,...
        'BiasInitializer', @(sz) zeros(sz))

    reluLayer('Name','relu_1')

    maxPooling2dLayer(2,'Stride',2,...
        'Name','maxpool_1')

    convolution2dLayer(3,16, 'Padding','same', 'Stride', [1 1], 'Name','conv_2',...
        'WeightsInitializer', @(sz) randn(sz)*0.01,...
        'BiasInitializer', @(sz) zeros(sz))

    reluLayer('Name','relu_2')

    maxPooling2dLayer(2,'Stride',2,...
        'Name','maxpool_2')

    convolution2dLayer(3,32, 'Padding','same', 'Stride', [1 1],...
        'Name','conv_3',...
        'WeightsInitializer', @(sz) randn(sz)*0.01,...
        'BiasInitializer', @(sz) zeros(sz))

    reluLayer('Name','relu_3')

    fullyConnectedLayer(15, 'Name','fc_1',...
        'WeightsInitializer', @(sz) randn(sz)*0.01,...
        'BiasInitializer', @(sz) zeros(sz))

    softmaxLayer('Name','softmax')
    classificationLayer('Name','output')
];

\end{lstlisting}

A peculiar aspects of this representation is the weights initialization, which is handled by the function handle \texttt{@(sz) randn(sz)*0.01}, which should yield proper random numbers for normally-distributed weights initialization with standard deviation $0.01$. 

Similarly, \texttt{@(sz) zeros(sz)} will generate the null vectors required to initialize the biases.

A name should be assigned to each layer, while the defined network may be visually inspected with the commands

\begin{lstlisting}
lgraph = layerGraph(layers);
analyzeNetwork(lgraph)
\end{lstlisting}

\subsection{Network training options}

Options for training the network should be provided. In order to satisfy the requirements, students set the following options in an object,

\begin{lstlisting}
options = trainingOptions('sgdm', ...
    'InitialLearnRate', InitialLearningRate, ...
    'ValidationData',imdsValidation, ... 
    'MiniBatchSize',32, ...
    'ExecutionEnvironment','parallel',...
    'Plots','training-progress'...
);

\end{lstlisting}

where the quantity \texttt{InitialLearningRate} should be properly fine-tuned.

Each option is necessary, with the sole exception of \texttt{ExecutionEnvironment}, which enables parallel computing capabilities:

\begin{itemize}
    \item \texttt{sgdm}: the optimization algorithm in use, as in requirements; 
    \item \texttt{ValidationData}: specifies the image datastore to use when validating the error, during the training;
    \item \texttt{MiniBatchSize}: set to $32$ as in requirements;
    \item \texttt{Plots}: enables a visual inspection of the training process, useful to spot possible signs of overfitting;
\end{itemize}

Every other option is left as default.

\subsection{Training the network and obtaining the accuracy}

The following command will begin the network training with specified layout and options,

\begin{lstlisting}
net = trainNetwork(imdsTrain, layers, options);
\end{lstlisting} 

In order to collect the accuracy with the provided test set, the students implemented the following code,

\begin{lstlisting}
TestDatasetPath = fullfile('dataset', 'test');
imdsTest = imageDatastore(TestDatasetPath, ...
    'IncludeSubfolders', true,...
    'LabelSource', 'foldernames');
imdsTest.ReadFcn = @(x)imresize(imread(x), [64 64]);

YPredicted = classify(net, imdsTest);
YTest = imdsTest.Labels;

accuracy = sum(YPredicted == YTest) / numel(YTest);
\end{lstlisting}

\subsection{Choice of \texttt{MaxEpoch} and stopping criterion}

Training the network with an initial learning rate of $0.001$ and leaving the default number of epochs unalterated led to evident overfitting of the network, as shown in Figure~\ref{fig:maxepoch-overfitting}.

\begin{figure}[ht]
        \centering
        \includegraphics[ width=1.0\linewidth, height=\textheight, keepaspectratio]{./pics/maxepoch-overfitting.png}
        \caption{Overfitting of the network when \texttt{MaxEpoch} is the default value of $30$.}
        \label{fig:maxepoch-overfitting}
\end{figure}

With the goal of avoiding overfitting, a lower \texttt{MaxEpoch} value (for instance $8$) should be adopted.

\subsection{Fine-tuning initial learning rate}

Fine-tune the initial learning rate required manual trials along with manual inspection. Values of $0.1$, $0.01$, $0.001$ and $0.0001$ (representatives of various order of magnitude) were tried. Only values in the neighborhood of $0.001$ gave the required performance of around $30\%$. Since the default \texttt{MaxEpoch} value of $30$ led to overfitting, a lower number should be set.

In particular, testing the network $5$ times, with an optimal initial learning rate of $0.0005$, $0.001$, $0.0015$ and $8$ epochs, collecting the accuracy of each run and averaging the results returned the following Table,

\bigskip

\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline 
Initial learning rate & Average of validation accuracy & Average of test set accuracy & Epochs \\
\hline \hline 
$0.0005$ & $0.2258$ & $0.1970$ & $8$ \\
\hline
$0.001$ & $0.2766$ & $0.2623$ & $8$ \\
\hline 
$0.0015$ & $0.2800$ & $0.2919$ & $8$ \\
\hline
\end{tabular}
\end{center}
\bigskip

Apparently, the baseline network of choice should be the third one with an initial learning rate of $0.0015$. However, the comparison is unfair since that network manifests signs of overfitting beginning with the Epoch $8$. To compare those two networks the group decided to lower the number of Epochs for the third network, and repeat the training:

\bigskip
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline 
Initial learning rate & Average of validation accuracy & Average of test set accuracy & Epochs \\
\hline \hline 
$0.001$ & $0.2766$ & $0.2623$ & $8$\\
\hline 
$0.0015$ & $0.2800$ & $0.2664$ & $7$\\
\hline
\end{tabular}
\end{center}
\bigskip

where in this case the choice makes no real difference with respect to the average of test set accuracy. To keep the baseline as simple as possible, the students decided to elect the first network as the \emph{baseline}, with parameters as following:

\bigskip
\begin{center}
\begin{tabular}{|c|c|}
\hline 
Baseline parameter & value \\
\hline \hline 
Optimization Algorithm & sgdm \\
\hline 
Epochs (stopping criterion) & $8$\\
\hline 
Initial Learning Rate & $0.001$\\
\hline
MiniBatch size & $32$ \\
\hline
Weights initialization & Gaussian with $\mu = 0$ and $\sigma = 0.01$\\
\hline 
Bias initialization & $0$\\
\hline
\end{tabular}
\end{center}
\bigskip

\subsection{Baseline confusion matrix}

To obtain the \emph{confusion matrix} for the chosen baseline network, the students ran the following code to first train the network again, and then plot a confusion matrix as shown in Figure~\ref{fig:baseline-confusion},

\begin{lstlisting}
InitialLearningRate = 0.001;
options = trainingOptions('sgdm', ...
    'InitialLearnRate', InitialLearningRate, ...
    'ValidationData',imdsValidation, ... 
    'MiniBatchSize',32, ...
    'MaxEpochs', 8,...
    'ExecutionEnvironment','parallel',...
    'Plots','training-progress'...
);

net = trainNetwork(imdsTrain,layers,options);

TestDatasetPath = fullfile('dataset','test');
imdsTest = imageDatastore(TestDatasetPath, ...
    'IncludeSubfolders',true,'LabelSource','foldernames');
imdsTest.ReadFcn = @(x)imresize(imread(x),[64 64]);

YPredicted = classify(net,imdsTest);
YTest = imdsTest.Labels;

accuracy = sum(YPredicted == YTest)/numel(YTest);

figure
plotconfusion(YTest,YPredicted)
\end{lstlisting}

\begin{figure}[ht]
        \centering
        \includegraphics[ width=1.0\linewidth, height=\textheight, keepaspectratio]{./pics/baseline-confusion.png}
        \caption{Confusion matrix for the baseline network.}
        \label{fig:baseline-confusion}
\end{figure}

The confusion matrix shows that there are some classes that are more often misclassified (\texttt{kitchen}, \texttt{industrial}) and some classes that instead are less often misclassified, such as \texttt{highway} and \texttt{street}. Overall accuracy stands at the value $28.9\%$: from this point of view, the baseline should represent an improvement from a completely random classifier, whose performance with respect to this classification task is less than~a~$7\%$.

\clearpage

\section{Improving the network}

The students propose (and have implemented) various methods in order to improve the performance of the Convolutional Neural Network from the baseline $\sim 30\%$ to a $60\%$:

\begin{enumerate}
    \item \emph{data augmentation};
    \item addition of \emph{batch normalization layers};
    \item changing the \emph{size of the convolutional filters};
    \item use of \emph{dropout layers}.
\end{enumerate}

Individual contribution and net improvement of each of these methods is not investigated \--- what is provided, instead, is a description of each technique's implementation along with the necessary details, a brief description of the increasing improvements \emph{at each added complexity} and a final overview of all improvements altogether with respect to the baseline. 

\subsection{Data augmentation}

The first improvement of the network is related to \emph{data augmentation}. The students implemented \emph{left-to-right reflections} of the train set, leaving unalterated the test set required for evaluation.

Running code 

\begin{lstlisting}
aug = imageDataAugmenter("RandXReflection",true);
imageSize = [64 64 1];
auimds = augmentedImageDatastore(imageSize,imdsTrain,'DataAugmentation',aug);
aunet = trainNetwork(auimds,layers,options);
\end{lstlisting}

with the same options as the baseline, but \texttt{MaxEpoch} set to $15$ (this kind of training resulted somehow to be slower), returned a validation accuracy of around $\sim 39\%$. Hence, the added complexity represented a slight improvement from the previous step.

Here are reported pictures of both training progress and confusion matrix,

TODO FIGURES

\subsection{Batch normalization}

The second improvement should consist in adding $3$ \textbf{Batch Normalization layers} before the ReLU layers. Each layer should be added into \texttt{layers} object, by adding line

\begin{lstlisting}
batchNormalizationLayer('Name','BN_1')
\end{lstlisting} 

before any ReLU layer. The name of the new layers should be changed accordingly to the place of those layers.

The added complexity resulted in a faster learning (a lower MaxEpoch number should be set, from $15$ to $6$) and a much higher accuracy ($51.11\%$ on validation set, $48.7\%$ on test data).

TODO FIGURES

\subsection{Improving convolution layers}

Convolution layers may be improved by increasing the size of the filter as they move towards the output. In practice, this means modifying the convolution layers such that their size increases from $3\times 3$ to $5\times 5$ and $7 \times 7$,

\begin{lstlisting}
convolution2dLayer(3,8,'Padding','same','Stride', [1 1], 'Name','conv_1',...
    'WeightsInitializer', @(sz) randn(sz)*0.01,...
    'BiasInitializer', @(sz) zeros(sz))

[...]

convolution2dLayer(5,16,'Padding','same','Stride', [1 1], 'Name','conv_2',...
    'WeightsInitializer',@(sz) randn(sz)*0.01,...
    'BiasInitializer', @(sz) zeros(sz))

[...]

 convolution2dLayer(7,32,'Padding','same','Stride', [1 1], 'Name','conv_3',...
    'WeightsInitializer', @(sz) randn(sz)*0.01,...
    'BiasInitializer', @(sz) zeros(sz))
\end{lstlisting}

This third addition brought a slight improvement, as the validation accuracy is at $55.11\%$, but the overall test accuracy stands at $50\%$.

TODO FIGURES

\subsection{Modifying parameters}

Editing the parameters should improve the performance of the network.

Parameters that should be subjected to optimization are, \emph{Minibatch Size} (default is $32$), \emph{Initial learning rate} (which was previously set to $0.001$), \emph{optimization algorithm} (`sgdm' or `adam'). Consequently, \emph{MaxEpoch} should be set accordingly, with the goal of avoiding overfitting while leaving the network room for enough complexity.

\subsection{Adding fully-connected and dropout layers}
\subsubsection{Minibatch size}
\subsubsection{Initial learning rate}
\subsubsection{Optimization algorithm}
\subsubsection{MaxEpoch}
\subsection{Adding convolutional layer}



 
\section{Adopting transfer learning with AlexNet}



\end{document}
